## Emotion-Based Music Recommendation using Reinforcement Learning
Recommendation systems are well-built because the Markov property is implemented in RL models. The song can be the state, while the action can be to offer the next best song, and the reward can be ratings, reviews, or user satisfaction in the RL problem. Every piece of data used to train the model can be transformed into a vector embedding, allowing us to see that the action space is continuous rather than discrete. Depending on the requirements, several embeddings can be created from the information, and this depends entirely on the subject matter expertise. Natural Language Understanding is a vast research field in and of itself, comprising several techniques for information extraction from the content. This idea has also been referred to as "maximisation of preserved information".

The Markov property states that a fresh recommendation supplied to a user, irrespective of earlier recommendations, is how the recommendation system problem should be interpreted. Another benefit of employing a reinforcement learning model in this situation is that it provides for the balance between exploitation and exploration. The algorithm will further suggest some random content to users in order to pique their interest. This is in addition to suggesting the users the songs that they find most fitting to their current mood. Reinforcement learning models will also be continuously learning. Hence, songs recommended will change as the user's mood change, which makes the model robust.
